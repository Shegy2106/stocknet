{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ticker = 'AAPL'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-02T12:48:53.076751Z",
     "start_time": "2024-08-02T12:48:53.069613Z"
    }
   },
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T12:48:53.563645Z",
     "start_time": "2024-08-02T12:48:53.561845Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from random import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def gen_int_random_size(size):\n",
    "    return int((random() * 100) % size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T12:48:54.030816Z",
     "start_time": "2024-08-02T12:48:54.027307Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_random_stock(ticker):\n",
    "    current_directory = os.getcwd()\n",
    "    preprocessed_directory = os.path.join(current_directory + \"/stocknet-dataset/price/preprocessed\")\n",
    "    files = os.listdir(preprocessed_directory)\n",
    "    # print(files)\n",
    "    \n",
    "# gen_int_random_size(len(directories))\n",
    "    random_file = os.path.join(preprocessed_directory, ticker + \".txt\")\n",
    "    print(random_file)\n",
    "    return random_file\n",
    "\n",
    "def load_into_pandas(filename):    \n",
    "    try:\n",
    "        columns = ['date', 'open_price', 'high_price', 'low_price', 'close_price', 'adj_close_price', 'volume']\n",
    "        df = pd.read_csv(filename, sep='\\t', header=None, names=columns, parse_dates=['date'])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T12:53:12.192765Z",
     "start_time": "2024-08-02T12:53:12.179392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/darkosegvic/PersonalDevelopment/stocknet/semantic-sentiment-analyst/stocknet-dataset/price/preprocessed/AAPL.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": "            open_price  high_price  low_price  close_price  adj_close_price  \\\ndate                                                                          \n2012-09-05   -0.007022    0.107768   0.109047     0.097979        -0.611802   \n2012-09-06    0.009012    0.111639   0.120094     0.107725         0.779618   \n2012-09-07    0.006166    0.109697   0.116947     0.105966         0.538215   \n2012-09-10   -0.026013    0.106800   0.111420     0.076953        -2.284607   \n2012-09-11   -0.003244    0.110742   0.119075     0.096363        -0.277496   \n...                ...         ...        ...          ...              ...   \n2017-08-28    0.010071    0.001752   0.013387     0.000438         1.610000   \n2017-08-29    0.008918   -0.008485   0.010219    -0.009104         1.440003   \n2017-08-30    0.002701    0.005463   0.006016    -0.001842         0.440002   \n2017-08-31    0.003979    0.001775   0.007163     0.000796         0.649994   \n2017-09-01    0.000305    0.004878   0.005732    -0.002256         0.050003   \n\n                 volume  \ndate                     \n2012-09-05   84093800.0  \n2012-09-06   97799100.0  \n2012-09-07   82416600.0  \n2012-09-10  121999500.0  \n2012-09-11  125995800.0  \n...                 ...  \n2017-08-28   25966000.0  \n2017-08-29   29516900.0  \n2017-08-30   27269600.0  \n2017-08-31   26785100.0  \n2017-09-01   16552800.0  \n\n[1257 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open_price</th>\n      <th>high_price</th>\n      <th>low_price</th>\n      <th>close_price</th>\n      <th>adj_close_price</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2012-09-05</th>\n      <td>-0.007022</td>\n      <td>0.107768</td>\n      <td>0.109047</td>\n      <td>0.097979</td>\n      <td>-0.611802</td>\n      <td>84093800.0</td>\n    </tr>\n    <tr>\n      <th>2012-09-06</th>\n      <td>0.009012</td>\n      <td>0.111639</td>\n      <td>0.120094</td>\n      <td>0.107725</td>\n      <td>0.779618</td>\n      <td>97799100.0</td>\n    </tr>\n    <tr>\n      <th>2012-09-07</th>\n      <td>0.006166</td>\n      <td>0.109697</td>\n      <td>0.116947</td>\n      <td>0.105966</td>\n      <td>0.538215</td>\n      <td>82416600.0</td>\n    </tr>\n    <tr>\n      <th>2012-09-10</th>\n      <td>-0.026013</td>\n      <td>0.106800</td>\n      <td>0.111420</td>\n      <td>0.076953</td>\n      <td>-2.284607</td>\n      <td>121999500.0</td>\n    </tr>\n    <tr>\n      <th>2012-09-11</th>\n      <td>-0.003244</td>\n      <td>0.110742</td>\n      <td>0.119075</td>\n      <td>0.096363</td>\n      <td>-0.277496</td>\n      <td>125995800.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2017-08-28</th>\n      <td>0.010071</td>\n      <td>0.001752</td>\n      <td>0.013387</td>\n      <td>0.000438</td>\n      <td>1.610000</td>\n      <td>25966000.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-29</th>\n      <td>0.008918</td>\n      <td>-0.008485</td>\n      <td>0.010219</td>\n      <td>-0.009104</td>\n      <td>1.440003</td>\n      <td>29516900.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-30</th>\n      <td>0.002701</td>\n      <td>0.005463</td>\n      <td>0.006016</td>\n      <td>-0.001842</td>\n      <td>0.440002</td>\n      <td>27269600.0</td>\n    </tr>\n    <tr>\n      <th>2017-08-31</th>\n      <td>0.003979</td>\n      <td>0.001775</td>\n      <td>0.007163</td>\n      <td>0.000796</td>\n      <td>0.649994</td>\n      <td>26785100.0</td>\n    </tr>\n    <tr>\n      <th>2017-09-01</th>\n      <td>0.000305</td>\n      <td>0.004878</td>\n      <td>0.005732</td>\n      <td>-0.002256</td>\n      <td>0.050003</td>\n      <td>16552800.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1257 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_file = load_random_stock(ticker)\n",
    "stock_df = load_into_pandas(stock_file)\n",
    "stock_df['date'] = pd.to_datetime(stock_df['date'])\n",
    "stock_df_sorted = stock_df.sort_values(by='date')\n",
    "stock_df_sorted = stock_df_sorted.reset_index(drop=True)\n",
    "stock_df_sorted.set_index('date', inplace=True)\n",
    "stock_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_earnings(ticker):\n",
    "    url = f'https://www.alphavantage.co/query?function=EARNINGS&symbol={ticker}&apikey=B0RLXVWXQMHH0LQD'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    print(data)\n",
    "    return data['quarterlyEarnings']\n",
    "\n",
    "# earnings = get_earnings(\"AAPL\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-02T12:48:57.886488Z",
     "start_time": "2024-08-02T12:48:57.883466Z"
    }
   },
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T12:54:00.151356Z",
     "start_time": "2024-08-02T12:54:00.138766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            adj_close_price reportedEPS  PE_ratio\ndate                                             \n2012-09-05        -0.611802        0.31 -1.973555\n2012-09-06         0.779618        0.31  2.514897\n2012-09-07         0.538215        0.31  1.736177\n2012-09-10        -2.284607        0.31 -7.369700\n2012-09-11        -0.277496        0.31 -0.895148\n...                     ...         ...       ...\n2017-08-28         1.610000      0.5175  3.111111\n2017-08-29         1.440003      0.5175  2.782614\n2017-08-30         0.440002      0.5175  0.850245\n2017-08-31         0.649994      0.5175  1.256027\n2017-09-01         0.050003      0.5175  0.096624\n\n[1257 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adj_close_price</th>\n      <th>reportedEPS</th>\n      <th>PE_ratio</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2012-09-05</th>\n      <td>-0.611802</td>\n      <td>0.31</td>\n      <td>-1.973555</td>\n    </tr>\n    <tr>\n      <th>2012-09-06</th>\n      <td>0.779618</td>\n      <td>0.31</td>\n      <td>2.514897</td>\n    </tr>\n    <tr>\n      <th>2012-09-07</th>\n      <td>0.538215</td>\n      <td>0.31</td>\n      <td>1.736177</td>\n    </tr>\n    <tr>\n      <th>2012-09-10</th>\n      <td>-2.284607</td>\n      <td>0.31</td>\n      <td>-7.369700</td>\n    </tr>\n    <tr>\n      <th>2012-09-11</th>\n      <td>-0.277496</td>\n      <td>0.31</td>\n      <td>-0.895148</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2017-08-28</th>\n      <td>1.610000</td>\n      <td>0.5175</td>\n      <td>3.111111</td>\n    </tr>\n    <tr>\n      <th>2017-08-29</th>\n      <td>1.440003</td>\n      <td>0.5175</td>\n      <td>2.782614</td>\n    </tr>\n    <tr>\n      <th>2017-08-30</th>\n      <td>0.440002</td>\n      <td>0.5175</td>\n      <td>0.850245</td>\n    </tr>\n    <tr>\n      <th>2017-08-31</th>\n      <td>0.649994</td>\n      <td>0.5175</td>\n      <td>1.256027</td>\n    </tr>\n    <tr>\n      <th>2017-09-01</th>\n      <td>0.050003</td>\n      <td>0.5175</td>\n      <td>0.096624</td>\n    </tr>\n  </tbody>\n</table>\n<p>1257 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from utils import load_json_to_dictionary\n",
    "\n",
    "earnings = load_json_to_dictionary(\"AAPL_earnings.json\")\n",
    "\n",
    "eps_df = pd.DataFrame(earnings)\n",
    "eps_df['fiscalDateEnding'] = pd.to_datetime(eps_df['fiscalDateEnding'])\n",
    "\n",
    "# Set the fiscalDateEnding as the index to align with stock_df_sorted\n",
    "eps_df.set_index('fiscalDateEnding', inplace=True)\n",
    "\n",
    "# print(eps_df.index)\n",
    "# print(stock_df_sorted['date'])\n",
    "# Reindex eps_df to match stock_df_sorted index, filling NaNs with forward fill method\n",
    "eps_df = eps_df.reindex(stock_df_sorted.index, method='ffill')\n",
    "\n",
    "# Concatenate the EPS data with the stock_df_sorted DataFrame\n",
    "stock_df_combined = pd.merge(left= stock_df_sorted, right=eps_df, left_index=True, right_index=True)\n",
    "\n",
    "# Calculate P/E Ratio\n",
    "stock_df_combined['PE_ratio'] = stock_df_combined['adj_close_price'] / stock_df_combined['reportedEPS'].astype(float)\n",
    "\n",
    "# Select the relevant columns and display the result\n",
    "stock_df_combined = stock_df_combined[['adj_close_price', 'reportedEPS', 'PE_ratio']]\n",
    "\n",
    "stock_df_combined\n",
    "# eps_df"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features\n",
    "df = stock_df_combined[['adj_close_price', 'PE_ratio']]\n",
    "# df = stock_df_combined[['adj_close_price']]\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# Create training and test data\n",
    "train_size = int(len(scaled_data) * 0.8)\n",
    "test_size = len(scaled_data) - train_size\n",
    "train_data, test_data = scaled_data[0:train_size, :], scaled_data[train_size - 30:, :]\n",
    "\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        a = dataset[i:(i + time_step)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])  \n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Reshape into X=t, t+1, t+2, ... t+n and Y=t+n+1\n",
    "time_step = 60\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], len(df.columns))\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], len(df.columns))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-02T12:57:06.764550Z",
     "start_time": "2024-08-02T12:57:06.760435Z"
    }
   },
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T12:56:26.777410Z",
     "start_time": "2024-08-02T12:56:12.939813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 14ms/step - loss: 0.2162 - val_loss: 0.0175\n",
      "Epoch 2/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0145 - val_loss: 0.0143\n",
      "Epoch 3/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0071 - val_loss: 0.0128\n",
      "Epoch 4/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0055 - val_loss: 0.0128\n",
      "Epoch 5/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0051 - val_loss: 0.0128\n",
      "Epoch 6/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0068 - val_loss: 0.0128\n",
      "Epoch 7/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0043 - val_loss: 0.0128\n",
      "Epoch 8/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0072 - val_loss: 0.0128\n",
      "Epoch 9/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0069 - val_loss: 0.0127\n",
      "Epoch 10/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0057 - val_loss: 0.0127\n",
      "Epoch 11/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0053 - val_loss: 0.0127\n",
      "Epoch 12/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0063 - val_loss: 0.0127\n",
      "Epoch 13/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0059 - val_loss: 0.0127\n",
      "Epoch 14/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0051 - val_loss: 0.0127\n",
      "Epoch 15/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0045 - val_loss: 0.0127\n",
      "Epoch 16/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0056 - val_loss: 0.0127\n",
      "Epoch 17/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0054 - val_loss: 0.0128\n",
      "Epoch 18/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0064 - val_loss: 0.0127\n",
      "Epoch 19/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0058 - val_loss: 0.0127\n",
      "Epoch 20/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0056 - val_loss: 0.0128\n",
      "Epoch 21/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0051 - val_loss: 0.0127\n",
      "Epoch 22/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0060 - val_loss: 0.0128\n",
      "Epoch 23/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0061 - val_loss: 0.0127\n",
      "Epoch 24/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0052 - val_loss: 0.0127\n",
      "Epoch 25/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0065 - val_loss: 0.0127\n",
      "Epoch 26/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0044 - val_loss: 0.0127\n",
      "Epoch 27/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0073 - val_loss: 0.0128\n",
      "Epoch 28/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0062 - val_loss: 0.0127\n",
      "Epoch 29/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0058 - val_loss: 0.0127\n",
      "Epoch 30/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0055 - val_loss: 0.0127\n",
      "Epoch 31/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0063 - val_loss: 0.0128\n",
      "Epoch 32/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0047 - val_loss: 0.0127\n",
      "Epoch 33/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0059 - val_loss: 0.0127\n",
      "Epoch 34/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0057 - val_loss: 0.0126\n",
      "Epoch 35/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0048 - val_loss: 0.0126\n",
      "Epoch 36/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0056 - val_loss: 0.0126\n",
      "Epoch 37/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0062 - val_loss: 0.0127\n",
      "Epoch 38/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0075 - val_loss: 0.0126\n",
      "Epoch 39/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0053 - val_loss: 0.0126\n",
      "Epoch 40/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0066 - val_loss: 0.0126\n",
      "Epoch 41/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0053 - val_loss: 0.0127\n",
      "Epoch 42/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0067 - val_loss: 0.0127\n",
      "Epoch 43/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0057 - val_loss: 0.0126\n",
      "Epoch 44/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0050 - val_loss: 0.0126\n",
      "Epoch 45/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0066 - val_loss: 0.0126\n",
      "Epoch 46/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0058 - val_loss: 0.0126\n",
      "Epoch 47/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0049 - val_loss: 0.0128\n",
      "Epoch 48/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0053 - val_loss: 0.0125\n",
      "Epoch 49/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0050 - val_loss: 0.0125\n",
      "Epoch 50/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0057 - val_loss: 0.0128\n",
      "Epoch 51/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0055 - val_loss: 0.0125\n",
      "Epoch 52/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0062 - val_loss: 0.0126\n",
      "Epoch 53/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0061 - val_loss: 0.0125\n",
      "Epoch 54/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0051 - val_loss: 0.0125\n",
      "Epoch 55/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0051 - val_loss: 0.0125\n",
      "Epoch 56/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0060 - val_loss: 0.0125\n",
      "Epoch 57/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0061 - val_loss: 0.0127\n",
      "Epoch 58/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0052 - val_loss: 0.0127\n",
      "Epoch 59/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0064 - val_loss: 0.0125\n",
      "Epoch 60/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0057 - val_loss: 0.0125\n",
      "Epoch 61/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0053 - val_loss: 0.0125\n",
      "Epoch 62/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0058 - val_loss: 0.0125\n",
      "Epoch 63/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0067 - val_loss: 0.0125\n",
      "Epoch 64/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0068 - val_loss: 0.0125\n",
      "Epoch 65/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0059 - val_loss: 0.0125\n",
      "Epoch 66/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0050 - val_loss: 0.0126\n",
      "Epoch 67/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0062 - val_loss: 0.0125\n",
      "Epoch 68/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0067 - val_loss: 0.0125\n",
      "Epoch 69/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0060 - val_loss: 0.0125\n",
      "Epoch 70/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0053 - val_loss: 0.0125\n",
      "Epoch 71/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0059 - val_loss: 0.0125\n",
      "Epoch 72/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0051 - val_loss: 0.0126\n",
      "Epoch 73/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0064 - val_loss: 0.0129\n",
      "Epoch 74/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0061 - val_loss: 0.0125\n",
      "Epoch 75/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0053 - val_loss: 0.0126\n",
      "Epoch 76/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0049 - val_loss: 0.0128\n",
      "Epoch 77/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0053 - val_loss: 0.0125\n",
      "Epoch 78/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0058 - val_loss: 0.0125\n",
      "Epoch 79/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0052 - val_loss: 0.0125\n",
      "Epoch 80/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0054 - val_loss: 0.0124\n",
      "Epoch 81/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0058 - val_loss: 0.0124\n",
      "Epoch 82/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0048 - val_loss: 0.0127\n",
      "Epoch 83/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0055 - val_loss: 0.0125\n",
      "Epoch 84/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0050 - val_loss: 0.0125\n",
      "Epoch 85/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0054 - val_loss: 0.0127\n",
      "Epoch 86/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0063 - val_loss: 0.0124\n",
      "Epoch 87/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0060 - val_loss: 0.0124\n",
      "Epoch 88/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0051 - val_loss: 0.0124\n",
      "Epoch 89/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0066 - val_loss: 0.0127\n",
      "Epoch 90/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0072 - val_loss: 0.0127\n",
      "Epoch 91/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0060 - val_loss: 0.0128\n",
      "Epoch 92/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0053 - val_loss: 0.0125\n",
      "Epoch 93/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0048 - val_loss: 0.0127\n",
      "Epoch 94/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0063 - val_loss: 0.0126\n",
      "Epoch 95/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0069 - val_loss: 0.0126\n",
      "Epoch 96/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0060 - val_loss: 0.0128\n",
      "Epoch 97/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0053 - val_loss: 0.0126\n",
      "Epoch 98/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0059 - val_loss: 0.0125\n",
      "Epoch 99/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0053 - val_loss: 0.0124\n",
      "Epoch 100/100\n",
      "\u001B[1m15/15\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0065 - val_loss: 0.0124\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x348da5880>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.models import simpleLSTM, stackedLSTM, bidirectionalLSTM, LSTMAttentionMechanism, encoderDecoderLSTM\n",
    "\n",
    "model = simpleLSTM(time_step, len(df.columns), 'adam', 'mean_squared_error')\n",
    "# model = encoderDecoderLSTM(time_step, 'adam', 'mean_squared_error')\n",
    "\n",
    "# model.fit(X_train, y_train,epochs = 100)\n",
    "model.fit(X_train, y_train,epochs = 100, validation_split=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "simpleLSTM  - 0.0054\n",
    "stackedLSTM - 0.0066\n",
    "bidirectionalLSTM - 0.0060\n",
    "attentionLSTM - 0.0062\n",
    "encoderDecoderLSTM - \n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Summary\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Invert predictions back to original scale\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_train_inv = scaler.inverse_transform([y_train])\n",
    "y_test_inv = scaler.inverse_transform([y_test])\n",
    "\n",
    "# Calculate RMSE performance metrics\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "train_rmse = math.sqrt(mean_squared_error(y_train_inv[0], train_predict[:,0]))\n",
    "test_rmse = math.sqrt(mean_squared_error(y_test_inv[0], test_predict[:,0]))\n",
    "print(f\"Train RMSE: {train_rmse}, Test RMSE: {test_rmse}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_train_inv[0], label='Actual Train')\n",
    "plt.plot(train_predict[:,0], label='Predicted Train')\n",
    "plt.plot(range(len(y_train_inv[0]), len(y_train_inv[0]) + len(y_test_inv[0])), y_test_inv[0], label='Actual Test')\n",
    "plt.plot(range(len(train_predict[:,0]), len(train_predict[:,0]) + len(test_predict[:,0])), test_predict[:,0], label='Predicted Test')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the last 30 days data\n",
    "last_30_days = scaled_data[-30:]\n",
    "X_input = last_30_days.reshape(1, -1)\n",
    "\n",
    "# Convert to the format accepted by the model\n",
    "temp_input = list(X_input)\n",
    "temp_input = temp_input[0].tolist()\n",
    "\n",
    "# Demonstrate prediction for next 30 days\n",
    "lst_output = []\n",
    "n_steps = 30\n",
    "i = 0\n",
    "while(i < 30):\n",
    "    \n",
    "    if(len(temp_input) > 30):\n",
    "        # Reshape and predict the next value\n",
    "        X_input = np.array(temp_input[1:])\n",
    "        X_input = X_input.reshape(1, -1)\n",
    "        X_input = X_input.reshape((1, n_steps, 1))\n",
    "        yhat = model.predict(X_input, verbose=0)\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        temp_input = temp_input[1:]\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i += 1\n",
    "    else:\n",
    "        X_input = X_input.reshape((1, n_steps, 1))\n",
    "        yhat = model.predict(X_input, verbose=0)\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i += 1\n",
    "\n",
    "# Transform the prediction back to the original scale\n",
    "final_output = scaler.inverse_transform(lst_output)\n",
    "\n",
    "# Visualize the prediction\n",
    "days = range(len(scaled_data), len(scaled_data) + 30)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(days, final_output, label='Predicted Next 30 Days')\n",
    "plt.title('Future Stock Price Prediction')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
